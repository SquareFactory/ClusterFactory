apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: slurm-cluster-exoscale-vie-app
  namespace: argocd
  finalizers:
    - resources-finalizer.argocd.argoproj.io
spec:
  project: slurm-cluster
  source:
    repoURL: git@github.com:squarefactory/cluster-factory-ce.git
    targetRevision: HEAD
    path: helm/slurm-cluster
    helm:
      releaseName: slurm-cluster-exoscale-vie

      values: |
        sssd:
          # secret containing sssd.conf
          # Will be mounted in /secrets/sssd
          secretName: sssd-secret

        munge:
          # secret containing munge.key
          # Will be mounted in /secrets/munge
          secretName: munge-secret

        slurmConfig:
          clusterName: exoscale-vie

          compute:
            srunPortRangeStart: 60001
            srunPortRangeEnd: 63000
            debug: debug5

          accounting: |
            AccountingStorageType=accounting_storage/slurmdbd
            AccountingStorageExternalHost=slurmdbd.csquare.gcloud:6819
            AccountingStorageHost=slurmdbd.csquare.gcloud
            AccountingStoragePort=6819
            AccountingStorageTRES=gres/gpu

          controller:
            parameters: enable_configless
            debug: debug5

          defaultResourcesAllocation: |
            DefCpuPerGPU=8
            DefMemPerCpu=1000

          nodes: |
            NodeName=cn-xxs-[1-10] Feature=cloud State=CLOUD Sockets=1 CoresPerSocket=1 ThreadsPerCore=1 RealMemory=384
            NodeName=cn-xs-[1-10] Feature=cloud State=CLOUD Sockets=1 CoresPerSocket=1 ThreadsPerCore=1 RealMemory=768
            NodeName=cn-s-[1-10] Feature=cloud State=CLOUD Sockets=2 CoresPerSocket=1 ThreadsPerCore=1 RealMemory=1200
            NodeName=cn-m-[1-10] Feature=cloud State=CLOUD Sockets=2 CoresPerSocket=1 ThreadsPerCore=1 RealMemory=3000
            NodeName=cn-l-[1-10] Feature=cloud State=CLOUD Sockets=4 CoresPerSocket=1 ThreadsPerCore=1 RealMemory=7000
            NodeName=cn-xl-[1-10] Feature=cloud State=CLOUD Sockets=4 CoresPerSocket=1 ThreadsPerCore=1 RealMemory=14500
            NodeName=cn-xxl-[1-10] Feature=cloud State=CLOUD Sockets=8 CoresPerSocket=1 ThreadsPerCore=1 RealMemory=29500
            NodeName=cn-sgpu2-[1-8] Feature=cloud,cuda State=CLOUD Sockets=12 CoresPerSocket=1 ThreadsPerCore=1 RealMemory=53500 Gres=gpu:1
            NodeName=cn-mgpu2-[1-4] Feature=cloud,cuda State=CLOUD Sockets=16 CoresPerSocket=1 ThreadsPerCore=1 RealMemory=85500 Gres=gpu:2
            NodeName=cn-lgpu2-[1-2] Feature=cloud,cuda State=CLOUD Sockets=24 CoresPerSocket=1 ThreadsPerCore=1 RealMemory=115500 Gres=gpu:3
            NodeName=cn-xlgpu2-1 Feature=cloud,cuda State=CLOUD Sockets=48 CoresPerSocket=1 ThreadsPerCore=1 RealMemory=217500 Gres=gpu:4

          partitions: |
            PartitionName=main Nodes=cn-xxs-[1-10],cn-xs-[1-10],cn-s-[1-10],cn-m-[1-10],cn-l-[1-10],cn-xl-[1-10],cn-xxl-[1-10],cn-sgpu2-[1-8],cn-mgpu2-[1-4],cn-lgpu2-[1-2],cn-xlgpu2-1 Default=YES MaxTime=INFINITE State=UP OverSubscribe=NO
            PartitionName=xxs Nodes=cn-xxs-[1-10] Default=NO MaxTime=INFINITE State=UP OverSubscribe=NO
            PartitionName=xs Nodes=cn-xs-[1-10] Default=NO MaxTime=INFINITE State=UP OverSubscribe=NO
            PartitionName=s Nodes=cn-s-[1-10] Default=NO MaxTime=INFINITE State=UP OverSubscribe=NO
            PartitionName=m Nodes=cn-m-[1-10] Default=NO MaxTime=INFINITE State=UP OverSubscribe=NO
            PartitionName=l Nodes=cn-l-[1-10] Default=NO MaxTime=INFINITE State=UP OverSubscribe=NO
            PartitionName=xl Nodes=cn-xl-[1-10] Default=NO MaxTime=INFINITE State=UP OverSubscribe=NO
            PartitionName=xxl Nodes=cn-xxl-[1-10] Default=NO MaxTime=INFINITE State=UP OverSubscribe=NO
            PartitionName=sgpu2 Nodes=cn-sgpu2-[1-8] Default=NO MaxTime=INFINITE State=UP OverSubscribe=NO
            PartitionName=mgpu2 Nodes=cn-mgpu2-[1-4] Default=NO MaxTime=INFINITE State=UP OverSubscribe=NO
            PartitionName=lgpu2 Nodes=cn-lgpu2-[1-2] Default=NO MaxTime=INFINITE State=UP OverSubscribe=NO
            PartitionName=xlgpu2 Nodes=cn-xlgpu2-1 Default=NO MaxTime=INFINITE State=UP OverSubscribe=NO

          gres: |
            NodeName=cn-sgpu2-[1-8] File=/dev/nvidia0 AutoDetect=nvml
            NodeName=cn-mgpu2-[1-4] File=/dev/nvidia[0-1] AutoDetect=nvml
            NodeName=cn-lgpu2-[1-2] File=/dev/nvidia[0-2] AutoDetect=nvml
            NodeName=cn-xlgpu2-1 File=/dev/nvidia[0-3] AutoDetect=nvml

          # Extra slurm.conf configuration
          extra: |
            CommunicationParameters=NoAddrCache
            #MailProg=/usr/bin/fakemail
            SuspendProgram=/slurm_powersave/suspend.sh
            ResumeProgram=/slurm_powersave/resume.sh
            SuspendExcNodes=slurm-headnode
            SuspendTime=180
            ResumeTimeout=600
            MessageTimeout=60

        controller:
          image: 'ghcr.io/squarefactory/slurm-docker:0.1.1-slurmctl-reindeer'
          replicas: 1

          command: ['sh', '-c', 'update-ca-trust && /init']

          imagePullSecrets:
            - name: ghcr-marc-secret

          persistence:
            storageClassName: ''
            accessModes: ['ReadWriteOnce']
            size: 50Gi
            selectorLabels:
              app: slurm-controller
              failure-domain.beta.kubernetes.io/region: ch-sion
              failure-domain.beta.kubernetes.io/zone: ch-sion-1

          initContainers:
            - name: init-perms-ssh
              image: busybox:1.34.1
              command:
                - sh
                - -c
                - |-
                  cp -RLp /in-ssh/* /out-ssh/
                  chmod -R 0600 /out-ssh/
              volumeMounts:
                - name: slurmctl-ssh
                  mountPath: /in-ssh
                - name: root-ssh-dir
                  mountPath: /out-ssh

          # secret containing jwt_hs256.key
          # Will be mounted in /secrets/slurm
          jwt:
            secretName: slurm-secret

          prologsConfigMap: 'slurmctl-reindeer-prologs'
          epilogsConfigMap: 'slurmctl-reindeer-epilogs'

          nodeSelector:
            failure-domain.beta.kubernetes.io/zone: ch-sion-1

          # Extra volume mounts
          volumeMounts:
            - name: root-ssh-dir
              mountPath: /root/.ssh
            - name: ca-cert
              mountPath: /etc/pki/ca-trust/source/anchors/csquare.gcloud.ca.pem
              subPath: csquare.gcloud.ca.pem

          # Extra volumes
          volumes:
            - name: slurmctl-ssh
              secret:
                secretName: slurmctl-ssh-secret
                defaultMode: 384
            - name: ca-cert
              secret:
                secretName: local-ca-secret
            - name: root-ssh-dir
              emptyDir:
                medium: "Memory"

          # Extra volume claims
          volumeClaimTemplates: []

          servicePerReplica:
            port: 6817
            loadBalancerIP: 10.10.2.152
            type: LoadBalancer

        login:
          enabled: true
          image: 'ghcr.io/squarefactory/slurm-docker:0.1.2-login-reindeer'
          replicas: 2

          command: ['sh', '-c', 'update-ca-trust && /init']

          imagePullSecrets:
            - name: ghcr-marc-secret

          sshd:
            secretName: login-sshd-secret

          nodeSelector:
            failure-domain.beta.kubernetes.io/zone: ch-sion-1

          # Extra volume mounts
          volumeMounts:
            - name: ca-cert
              mountPath: /etc/pki/ca-trust/source/anchors/csquare.gcloud.ca.pem
              subPath: csquare.gcloud.ca.pem
            - name: slurm-login-reindeer-profile
              mountPath: /etc/profile.d/z00_lmod.sh
              subPath: z00_lmod.sh
            - name: slurm-login-reindeer-profile
              mountPath: /etc/profile.d/z01_lmod_env.sh
              subPath: z01_lmod_env.sh
            - name: slurm-login-reindeer-contlist
              mountPath: /usr/local/bin/contlist
              subPath: contlist
            - name: ldap-users-reindeer-pvc
              mountPath: /home/ldap-users
            - name: jobs-logs-reindeer-pvc
              mountPath: /opt/jobs-logs
            - name: images-reindeer-pvc
              mountPath: /opt/images
            - name: experiments-reindeer-pvc
              mountPath: /opt/experiments
            - name: software-sion-csquare-run
              mountPath: /opt/software
            - name: stdenv-sion-csquare-run
              mountPath: /opt/stdenv
            - name: unpacked-sion-csquare-run
              mountPath: /opt/unpacked

          # Extra volumes
          volumes:
            - name: ca-cert
              secret:
                secretName: local-ca-secret
            - name: slurm-login-reindeer-profile
              configMap:
                name: slurm-login-reindeer-profile
                defaultMode: 493
            - name: slurm-login-reindeer-contlist
              configMap:
                name: slurm-login-reindeer-contlist
                defaultMode: 493
            - name: software-sion-csquare-run
              hostPath:
                path: /cvmfs/software.sion.csquare.run
                type: Directory
            - name: stdenv-sion-csquare-run
              hostPath:
                path: /cvmfs/stdenv.sion.csquare.run
                type: Directory
            - name: unpacked-sion-csquare-run
              hostPath:
                path: /cvmfs/unpacked.sion.csquare.run
                type: Directory
            - name: ldap-users-reindeer-pvc
              persistentVolumeClaim:
                claimName: ldap-users-reindeer-pvc
            - name: experiments-reindeer-pvc
              persistentVolumeClaim:
                claimName: experiments-reindeer-pvc
            - name: images-reindeer-pvc
              persistentVolumeClaim:
                claimName: images-reindeer-pvc
            - name: jobs-logs-reindeer-pvc
              persistentVolumeClaim:
                claimName: jobs-logs-reindeer-pvc

          # Extra volume claims
          volumeClaimTemplates: []

          net:
            # Kubernetes host interface
            masterInterface: eno2
            mode: bridge

            # https://www.cni.dev/plugins/current/ipam/static/
            ipam:
              type: host-local
              ranges:
                - - subnet: 10.10.2.0/24
                    rangeStart: 10.10.2.46
                    rangeEnd: 10.10.2.47
                    gateway: 10.10.2.1
              dataDir: "/tmp/slurm-ips-state"

  destination:
    server: 'https://kubernetes.default.svc'
    namespace: slurm-cluster

  syncPolicy:
    automated:
      prune: false # Specifies if resources should be pruned during auto-syncing ( false by default ).
      selfHeal: true # Specifies if partial app sync should be executed when resources are changed only in target Kubernetes cluster and no git change detected ( false by default ).
      allowEmpty: false # Allows deleting all application resources during automatic syncing ( false by default ).
    syncOptions: []
    retry:
      limit: 5 # number of failed sync attempt retries; unlimited number of attempts if less than 0
      backoff:
        duration: 5s # the amount to back off. Default unit is seconds, but could also be a duration (e.g. "2m", "1h")
        factor: 2 # a factor to multiply the base duration after each failed retry
        maxDuration: 3m # the maximum amount of time allowed for the backoff strategy
