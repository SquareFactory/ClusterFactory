"use strict";(self.webpackChunkcluster_factory_ce_docs=self.webpackChunkcluster_factory_ce_docs||[]).push([[696],{7942:(e,t,n)=>{n.d(t,{Zo:()=>c,kt:()=>d});var a=n(959);function o(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function r(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function l(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?r(Object(n),!0).forEach((function(t){o(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):r(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},r=Object.keys(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}var s=a.createContext({}),p=function(e){var t=a.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):l(l({},t),e)),n},c=function(e){var t=p(e.components);return a.createElement(s.Provider,{value:t},e.children)},u={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},m=a.forwardRef((function(e,t){var n=e.components,o=e.mdxType,r=e.originalType,s=e.parentName,c=i(e,["components","mdxType","originalType","parentName"]),m=p(n),d=o,h=m["".concat(s,".").concat(d)]||m[d]||u[d]||r;return n?a.createElement(h,l(l({ref:t},c),{},{components:n})):a.createElement(h,l({ref:t},c))}));function d(e,t){var n=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var r=n.length,l=new Array(r);l[0]=m;var i={};for(var s in t)hasOwnProperty.call(t,s)&&(i[s]=t[s]);i.originalType=e,i.mdxType="string"==typeof e?e:o,l[1]=i;for(var p=2;p<r;p++)l[p]=n[p];return a.createElement.apply(null,l)}return a.createElement.apply(null,n)}m.displayName="MDXCreateElement"},4216:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>s,contentTitle:()=>l,default:()=>u,frontMatter:()=>r,metadata:()=>i,toc:()=>p});var a=n(665),o=(n(959),n(7942));const r={},l="Deploying a Rook Cluster",i={unversionedId:"guides/storage/deploying-rook-cluster",id:"guides/storage/deploying-rook-cluster",title:"Deploying a Rook Cluster",description:"Configuration",source:"@site/docs/guides/90-storage/04-deploying-rook-cluster.md",sourceDirName:"guides/90-storage",slug:"/guides/storage/deploying-rook-cluster",permalink:"/docs/guides/storage/deploying-rook-cluster",draft:!1,editUrl:"https://github.com/deepsquare-io/ClusterFactory/tree/main/web/docs/guides/90-storage/04-deploying-rook-cluster.md",tags:[],version:"current",sidebarPosition:4,frontMatter:{},sidebar:"docs",previous:{title:"Deploying the Rook Operator",permalink:"/docs/guides/storage/deploying-rook"},next:{title:"Claiming a volume",permalink:"/docs/guides/storage/claiming-volume"}},s={},p=[{value:"Configuration",id:"configuration",level:2},{value:"Exposing to the external network using Multus (experimental)",id:"exposing-to-the-external-network-using-multus-experimental",level:2},{value:"Deploy the cluster",id:"deploy-the-cluster",level:2}],c={toc:p};function u(e){let{components:t,...n}=e;return(0,o.kt)("wrapper",(0,a.Z)({},c,n,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("h1",{id:"deploying-a-rook-cluster"},"Deploying a Rook Cluster"),(0,o.kt)("h2",{id:"configuration"},"Configuration"),(0,o.kt)("ol",null,(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"Deploy the ArgoCD AppProject and namespace first:"),(0,o.kt)("pre",{parentName:"li"},(0,o.kt)("code",{parentName:"pre",className:'language-title="user@local:/ClusterFactory"'},"kubectl apply -f argo/rook-ceph-cluster\n"))),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"Create a values file based on the example in the ",(0,o.kt)("inlineCode",{parentName:"p"},"helm-subcharts/rook-ceph-cluster")," directory:"),(0,o.kt)("pre",{parentName:"li"},(0,o.kt)("code",{parentName:"pre",className:"language-shell",metastring:'title="user@local:/ClusterFactory"',title:'"user@local:/ClusterFactory"'},"cp helm-subcharts/rook-ceph-cluster/values-example.yaml helm-subcharts/rook-ceph-cluster/values-production.yaml\n"))),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"Edit the values file."),(0,o.kt)("ol",{parentName:"li"},(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"If your storage plane is less than 3 nodes, enable the ",(0,o.kt)("inlineCode",{parentName:"p"},"allowMultiplePerNode")," for MONs and MGRs, or reduce the number of replicas.")),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},(0,o.kt)("strong",{parentName:"p"},"Configure the ",(0,o.kt)("inlineCode",{parentName:"strong"},"rook-ceph-cluster.cephClusterSpec.storage")," to filter the disk"),":"),(0,o.kt)("pre",{parentName:"li"},(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},'storage:\n  useAllNodes: false\n  useAllDevices: false\n  deviceFilter: \'\' # You can filter using regex, like this: `^vdb$` will use /dev/vdb\n  # config:\n  #   crushRoot: "custom-root" # specify a non-default root label for the CRUSH map\n  #   metadataDevice: "md0" # specify a non-rotational storage so ceph-volume will use it as block db device of bluestore.\n  #   databaseSizeMB: "1024" # uncomment if the disks are smaller than 100 GB\n  #   osdsPerDevice: "1" # this value can be overridden at the node or device level\n  #   encryptedDevice: "true" # the default value for this option is "false"\n  # # Individual nodes and their config can be specified as well, but \'useAllNodes\' above must be set to false. Then, only the named\n  # # nodes below will be used as storage resources. Each node\'s \'name\' field should match their \'kubernetes.io/hostname\' label.\n  # nodes:\n  #   - name: "172.17.4.201"\n  #     devices: # specific devices to use for storage can be specified for each node\n  #       - name: "sdb"\n  #       - name: "nvme01" # multiple osds can be created on high performance devices\n  #         config:\n  #           osdsPerDevice: "5"\n  #       - name: "/dev/disk/by-id/ata-ST4000DM004-XXXX" # devices can be specified using full udev paths\n  #     config: # configuration can be specified at the node level which overrides the cluster level config\n  #   - name: "172.17.4.301"\n  #     deviceFilter: "^sd."\n'))),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"You can configure the ",(0,o.kt)("inlineCode",{parentName:"p"},"ingress")," and CoreDNS if you wish to access the dashboard.")),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},(0,o.kt)("strong",{parentName:"p"},"If you wish for a Rados Block Device (RBD)"),", which is used for ",(0,o.kt)("inlineCode",{parentName:"p"},"ReadWriteOnce")," volumes, uncomment the ",(0,o.kt)("inlineCode",{parentName:"p"},"cephBlockPools")," fields. Refer to the official ",(0,o.kt)("a",{parentName:"p",href:"https://rook.io/docs/rook/latest/Storage-Configuration/Block-Storage-RBD/block-storage/"},"Rook documentation")," for configuration details.")),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},(0,o.kt)("strong",{parentName:"p"},"If you wish for a CephFS"),", which is used for ",(0,o.kt)("inlineCode",{parentName:"p"},"ReadWriteMany")," or ",(0,o.kt)("inlineCode",{parentName:"p"},"ReadWriteOnce")," volumes, uncomment the ",(0,o.kt)("inlineCode",{parentName:"p"},"cephFileSystems")," fields. Refer to the official ",(0,o.kt)("a",{parentName:"p",href:"https://rook.io/docs/rook/latest/Storage-Configuration/Shared-Filesystem-CephFS/filesystem-storage/"},"Rook documentation")," for configuration details.")),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},(0,o.kt)("strong",{parentName:"p"},"If you wish for a Object Storage (Rados GateWay, RGW)"),", uncomment the ",(0,o.kt)("inlineCode",{parentName:"p"},"cephObjectStores")," fields. Refer to the official ",(0,o.kt)("a",{parentName:"p",href:"https://rook.io/docs/rook/latest/Storage-Configuration/Object-Storage-RGW/object-storage/"},"Rook documentation")," for configuration details. You can expose the RGW by filling the ",(0,o.kt)("inlineCode",{parentName:"p"},"ingress")," field. Beware of the ",(0,o.kt)("inlineCode",{parentName:"p"},"erasureCoded")," field which may require you to have at least 3 OSDs. If you are lacking in OSDs, you can enable the ",(0,o.kt)("inlineCode",{parentName:"p"},"osdsPerDevice")," in the storage configuration fields."))))),(0,o.kt)("h2",{id:"exposing-to-the-external-network-using-multus-experimental"},"Exposing to the external network using Multus (experimental)"),(0,o.kt)("p",null,"Rook offers these solutions to expose Rook to the external:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Using ",(0,o.kt)("inlineCode",{parentName:"li"},"LoadBalancer")," Services or Ingresses."),(0,o.kt)("li",{parentName:"ul"},"Using the ",(0,o.kt)("inlineCode",{parentName:"li"},"host")," network by setting the value of ",(0,o.kt)("inlineCode",{parentName:"li"},"rook-ceph-cluster.cephClusterSpec.network.provider")," to ",(0,o.kt)("inlineCode",{parentName:"li"},"host"),"."),(0,o.kt)("li",{parentName:"ul"},"Using Multus CNI by setting the value of ",(0,o.kt)("inlineCode",{parentName:"li"},"rook-ceph-cluster.cephClusterSpec.network.provider")," to ",(0,o.kt)("inlineCode",{parentName:"li"},"multus")," (which is experimental). (You can follow more details here: ",(0,o.kt)("a",{parentName:"li",href:"https://www.youtube.com/watch?v=zIS5qaG_HRw"},"CNCF video"),", ",(0,o.kt)("a",{parentName:"li",href:"https://github.com/rook/rook/blob/master/design/ceph/multus-network.md"},"design"),")")),(0,o.kt)("p",null,"We will focus on the ",(0,o.kt)("strong",{parentName:"p"},"Multus")," solution as it offers the least of packet encapsulation and gives the best performance:"),(0,o.kt)("ol",null,(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"Install the ",(0,o.kt)("a",{parentName:"p",href:"https://github.com/k8snetworkplumbingwg/whereabouts"},"Whereabouts IPAM plugin")," (this is an alternative to the ",(0,o.kt)("a",{parentName:"p",href:"https://www.cni.dev/plugins/current/ipam/host-local/"},(0,o.kt)("inlineCode",{parentName:"a"},"host-local")," IPAM plugin"),") by applying:"),(0,o.kt)("pre",{parentName:"li"},(0,o.kt)("code",{parentName:"pre",className:"language-shell",metastring:'title="user@local:/ClusterFactory"',title:'"user@local:/ClusterFactory"'},"kubectl -k core/whereabouts\n")),(0,o.kt)("p",{parentName:"li"},"You can add these lines to the ",(0,o.kt)("inlineCode",{parentName:"p"},"scripts/deploy-core")," script if you want to keep track of these deployments."),(0,o.kt)("admonition",{parentName:"li",type:"info"},(0,o.kt)("p",{parentName:"admonition"},"To add further detail: ",(0,o.kt)("inlineCode",{parentName:"p"},"host-local")," is used to give IPs to pods within a certain range. It's very similar to DHCP, without the need to use a DHCP server. One difficulty with ",(0,o.kt)("inlineCode",{parentName:"p"},"host-local")," is that the IP allocation state is stored in a file, which is not extensible and does not work on multiple nodes."),(0,o.kt)("p",{parentName:"admonition"},"The ",(0,o.kt)("inlineCode",{parentName:"p"},"whereabouts")," IPAM plugin uses the etcd database instead of files. And by using CRDs, it can integrate with the Kubernetes database."))),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"Create two ",(0,o.kt)("inlineCode",{parentName:"p"},"NetworkAttachmentDefinition")," in the ",(0,o.kt)("inlineCode",{parentName:"p"},"argo.example/rook-ceph-cluster/network")," directory:"),(0,o.kt)("pre",{parentName:"li"},(0,o.kt)("code",{parentName:"pre",className:"language-yaml",metastring:'title="argo/rook-ceph-cluster/network/rook-public-net.yaml"',title:'"argo/rook-ceph-cluster/network/rook-public-net.yaml"'},'apiVersion: \'k8s.cni.cncf.io/v1\'\nkind: NetworkAttachmentDefinition\nmetadata:\n  name: rook-public-net\n  namespace: rook-ceph-cluster\nspec:\n  config: |\n    {\n      "cniVersion": "0.3.0",\n      "type": "ipvlan",\n      "master": "eth0",\n      "ipam":{\n        "type":"whereabouts",\n        "range": "192.168.0.0/24",\n        "exclude": [\n          "192.168.0.0/30"\n        ]\n      }\n    }\n')),(0,o.kt)("p",{parentName:"li"},"This network is used by the clients. Clients in the ",(0,o.kt)("inlineCode",{parentName:"p"},"192.168.0.0/24")," will be able to communicate with the Ceph cluster."),(0,o.kt)("pre",{parentName:"li"},(0,o.kt)("code",{parentName:"pre",className:"language-yaml",metastring:'title="argo/rook-ceph-cluster/network/rook-cluster-net.yaml"',title:'"argo/rook-ceph-cluster/network/rook-cluster-net.yaml"'},'apiVersion: \'k8s.cni.cncf.io/v1\'\nkind: NetworkAttachmentDefinition\nmetadata:\n  name: rook-cluster-net\n  namespace: rook-ceph-cluster\nspec:\n  config: |\n    {\n      "cniVersion": "0.3.0",\n      "type": "ipvlan",\n      "master": "eth0",\n      "ipam":{\n        "type":"whereabouts",\n        "range": "10.11.0.0/24"\n      }\n    }\n')),(0,o.kt)("p",{parentName:"li"},(0,o.kt)("strong",{parentName:"p"},"Change the IPAM ",(0,o.kt)("inlineCode",{parentName:"strong"},"range")," and ",(0,o.kt)("inlineCode",{parentName:"strong"},"excludes")," accordingly. Also set the ",(0,o.kt)("inlineCode",{parentName:"strong"},"master")," interface with a host interface. You can use two network interfaces to separate the public and cluster network.")),(0,o.kt)("p",{parentName:"li"},"The ",(0,o.kt)("inlineCode",{parentName:"p"},"rook-cluster-net")," is used internally by the daemons to communicate. While you could use ",(0,o.kt)("inlineCode",{parentName:"p"},"rook-public-net"),", the Rook developers reported that using two networks is more performant."),(0,o.kt)("p",{parentName:"li"},"And apply them:"),(0,o.kt)("pre",{parentName:"li"},(0,o.kt)("code",{parentName:"pre",className:"language-shell",metastring:'title="user@local:/ClusterFactory"',title:'"user@local:/ClusterFactory"'},"kubectl -k argo/rook-ceph-cluster/network/\n"))),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"Uncomment the ",(0,o.kt)("inlineCode",{parentName:"p"},"provider: multus")," field and set the selectors to:"),(0,o.kt)("pre",{parentName:"li"},(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},"network:\n  # ...\n  provider: multus\n  selectors:\n    public: rook-ceph-cluster/rook-public-net\n    cluster: rook-ceph-cluster/rook-cluster-net\n")))),(0,o.kt)("h2",{id:"deploy-the-cluster"},"Deploy the cluster"),(0,o.kt)("p",null,"Configure the Argo CD Application:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml",metastring:'title="argo.example/rook-ceph-cluster/apps/app.yaml"',title:'"argo.example/rook-ceph-cluster/apps/app.yaml"'},'apiVersion: argoproj.io/v1alpha1\nkind: Application\nmetadata:\n  name: rook-ceph-cluster-app\n  namespace: argocd\n  finalizers:\n    - resources-finalizer.argocd.argoproj.io\nspec:\n  project: rook-ceph-cluster\n  source:\n    # You should have forked this repo. Change the URL to your fork.\n    repoURL: git@github.com:<your account>/<your repo>.git\n    # You should use your branch too.\n    targetRevision: HEAD\n    path: helm/rook-ceph-cluster\n    helm:\n      releaseName: rook-ceph-cluster\n\n      # Create a values file inside your fork and change the values.\n      valueFiles:\n        - values-production.yaml\n\n  destination:\n    server: \'https://kubernetes.default.svc\'\n    namespace: rook-ceph-cluster\n\n  syncPolicy:\n    automated:\n      prune: true # Specifies if resources should be pruned during auto-syncing ( false by default ).\n      selfHeal: true # Specifies if partial app sync should be executed when resources are changed only in target Kubernetes cluster and no git change detected ( false by default ).\n      allowEmpty: false # Allows deleting all application resources during automatic syncing ( false by default ).\n    syncOptions: []\n    retry:\n      limit: 5 # number of failed sync attempt retries; unlimited number of attempts if less than 0\n      backoff:\n        duration: 5s # the amount to back off. Default unit is seconds, but could also be a duration (e.g. "2m", "1h")\n        factor: 2 # a factor to multiply the base duration after each failed retry\n        maxDuration: 3m # the maximum amount of time allowed for the backoff strategy\n')),(0,o.kt)("p",null,"And apply it:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-shell",metastring:'title="user@local:/ClusterFactory"',title:'"user@local:/ClusterFactory"'},"kubectl apply -f argo/rook-ceph-cluster/apps\n")),(0,o.kt)("p",null,"You should monitor the deployment with Lens."))}u.isMDXComponent=!0}}]);